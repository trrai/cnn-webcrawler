# INFO 344 PA4:  search_

## Website Link
[Link to working website](http://pa4search.cloudapp.net/search.html)


## Screenshots
![Dashboard Picture](https://i.imgur.com/BcJJyDZ.jpg)
![Interface Picture](https://i.imgur.com/8BydK0S.jpg)

## Write up
For this assignment, I worked on combining the hard work from the past couple months into a fully functional search engine. Taking concepts from programming assignments 1, 2, and 3, I was able to apply search functionality to a CNN/Bleacher Report web crawler and a hosted NBA Player API. In my process of development, I first began by modifying the first assignment so it would act more like an API rather than returning a searchable html page. This meant changing the php code hosted on AWS to return JSONP data and restricting searches to exact names. To achieve this, I changed the method in my php file to construct an NBA Player object, serialize this object and return it as JSONP to the requester. After the modification, I redeployed on AWS and made sure my API requests were properly returning NBA player statistics. With the PA1 portion complete, I moved on to working on the web crawler. Since the functionality of the crawler is now focused on searching keywords, I had to change the structure of how results were being tabled in order to optimize search for relevancy and speed. To achieve this, I changed my partitionkey to represent a keyword and the rowkey to be a MD5 Hash of the associated link. Therefore when a URL is crawled, the link is stored in the table for each word within the title. This format gave the quickest access possible even with 1m+ table rows. With the results now reformatted, I needed to create a method in my ASMX file which would query the table with user input and return the most relevant 25 results. This involved running a table query for each keyword inputted and combining these results into a singular list. After the list was constructed, I used a LINQ statement to order first by count of user keywords within the title, and then order by the publishing date in case of a tie. Incorporating this sorting functionality really pushed the project to resemble a search engine and drastically improved user experience. After this, I began on my front-end where the user will be interacting with the data. My layout was fairly simple and is made up of the project logo with a input group underneath. Below the input group is where I included the preformatted script to include google ads. When adblock is fully disabled, ads will be auto-generated and shown to the user. When the submit button is clicked, ajax requests are sent to the PA1 API for nba players and to the ASMX method that searches the table. If an NBA player is found, then the results are displayed in a bootstrap table right underneath the input group. Underneath this is where news results are shown! After the data is returned from the ASMX method as a JSON object, javascript code parses the information and appropriately appends each result to its own bootstrap card. In case results are not found, then a “not found” image will be displayed instead. The PA2 portion of project did not involve much change during incorporation; it was moreover transitioning the code into the cloud web application. On each keypress of the input bar, an ajax request is sent to a method in the ASMX file that searches the trie for 10 words that contain the user input prefix. With the returned JSON, each element is appended underneath the input group and shown as search suggestions. All in all, this project was an amazing experience and really tied together the concepts covered over the past two months!

## Extra Credit Write up
The extra credits for this assignment is where I spent a large majority of time and I believe it drastically improved the user experience associated with the project. First, I aimed for the beautiful search results page requirement by incorporating elements that improved aesthetics. I began by changing my crawling code so it would index both the image and body text of the articles it would crawl. CNN was very user-friendly with this process and I was easily able to grab information from the metadata on each url. After storing these two elements, I changed my front end to render a bootstrap card that includes the title, image, publishing date, body text preview, and link to visit the full article for each returned result. I found that incorporating the body text preview and image with each result drastically improves usability and makes parsing the results a lot more efficient. To further improve usability of my project, I incorporated a loading animation that appears when the submit button is clicked and turned hidden after the ajax request is returned. In addition, if a user searches something that is not associated to any results in the table, an image is displayed letting them know. All in all, front end design was completed largely through the Bootstrap library and making use of UX design choices for color and layout. My second extra credit implementation comes in the form of bolding query words in the body text. Since I already had access to the body text after modifying my web crawler, I used regex to find case insensitive occurrences of keywords and replaced the instances with the word surrounded with <b> tags. This process took minimal effort but was immensely rewarding in terms of user experience. Seeing the words that were searched for drastically improves ability to parse results. 